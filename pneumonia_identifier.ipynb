{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd33458f",
   "metadata": {},
   "source": [
    "# Identifying Pneumonia with CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f10f790",
   "metadata": {},
   "source": [
    "### Deep Learning-Based Pneumonia Diagnosis from Chest X-ray Images | Transfer Learning & Keras Tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62956e17",
   "metadata": {},
   "source": [
    "This project aims to develop an accurate and efficient machine learning model for the early detection and diagnosis of pneumonia using deep learning techniques. It's prompted by Kaggle's Chest-X-Ray Pneumonia Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8271aac9",
   "metadata": {},
   "source": [
    "**From Kaggle:**\n",
    "\n",
    "*\"The dataset is meticulously organized into three folders: train, test, and validation. Each folder contains subfolders for each image category, namely Pneumonia and Normal. The dataset comprises 5,863 X-Ray images (JPEG format) across two categories (Pneumonia/Normal).\n",
    "The chest X-ray images (anterior-posterior) were selected from retrospective cohorts of pediatric patients aged one to five years old from the Guangzhou Women and Childrenâ€™s Medical Center, Guangzhou. All chest X-ray imaging was performed as part of the patients' routine clinical care.\"*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07417034",
   "metadata": {},
   "source": [
    "## Filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "793ef2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 \n",
    "\n",
    "current_path = os.getcwd()\n",
    "\n",
    "testing_path = f\"{current_path}/test\"\n",
    "training_path = f\"{current_path}/train\"\n",
    "validation_path = f\"{current_path}/val\"\n",
    "\n",
    "# print(\"File Paths:\",\n",
    "#       f\"Testing: {testing_path}\",\n",
    "#       f\"Training: {training_path}\"\n",
    "# ,\n",
    "#       f\"Validation: {validation_path}\",\n",
    "#       sep=\"\\n\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a3e231",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f2424e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c403b2",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97a98fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras import Sequential\n",
    "from keras.layers import Activation, BatchNormalization, Conv2D, Dense, Dropout, Flatten, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52803aa",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2f6c6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD,RMSprop, Adadelta, Nadam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe70959",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7db23dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12a9455",
   "metadata": {},
   "source": [
    "## Loading Data into Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6093c9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The images are 2090x1858\n"
     ]
    }
   ],
   "source": [
    "# Collecting current image sizes:\n",
    "files = (os.listdir(f\"{training_path}/normal\"))\n",
    "\n",
    "image = cv2.imread(f\"{training_path}/normal/{files[0]}\")\n",
    "width = image.shape[1]\n",
    "height = image.shape[0]\n",
    "\n",
    "print(\"The images are {}x{}\".format(width, height)) # Too big, recommended reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7391a038",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (255, 255)\n",
    "BATCH_SIZE = 32\n",
    "SEED_TRAIN = 7 # Enables reproducibility of experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c52c5d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 files belonging to 2 classes.\n",
      "Found 16 files belonging to 2 classes.\n",
      "Found 624 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Using Keras to collect the data from the directories. It automatically recognizes the classification \"normal\", \"pneumonia\"\n",
    "\n",
    "training_dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=training_path,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=SEED_TRAIN,\n",
    "    color_mode='rgb', # (255, 255, 255) x 3-Dimensional Output\n",
    "    label_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=validation_path,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=SEED_TRAIN,\n",
    "    color_mode='rgb',\n",
    "    label_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "testing_dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=testing_path,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=SEED_TRAIN,\n",
    "    color_mode='rgb',\n",
    "    label_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227701a9",
   "metadata": {},
   "source": [
    "## Pretrained ResNet Model with Keras Tuner - Transfered Learning & HP Optimization\n",
    "\n",
    "[Keras Tuner Documentation](https://keras.io/keras_tuner/) -> A Tuner Searches for the best architecture (hyperparameters) for the model, including number of perceptrons, the best optimizer and the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6624912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner\n",
    "from keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1541865a",
   "metadata": {},
   "source": [
    "### Step 1: Define Tuner Function with all Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58587fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    \"\"\"Params: hp, hyperparameters\"\"\"\n",
    "    \n",
    "    LEARNING_RATES = [1e-2, 1e-3, 1e-4] # Optimizers learning rate\n",
    "    \n",
    "    # Initialize pretrained model to build on top of\n",
    "    pretrained_model = ResNet50(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3) # rgb dimensions\n",
    "    )\n",
    "    \n",
    "    # Freeze the layers of the pre-trained model! It doesn't need fine-tuning\n",
    "    for layer in pretrained_model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    # Flattening the Output of ResNet50 to add to next layer:\n",
    "    output = pretrained_model.output\n",
    "    output = Dropout(0.2)(output)\n",
    "    output = Flatten()(output)\n",
    "    \n",
    "    preds = Dense(2, activation='softmax')(output) # 2: normal, pneumonia\n",
    "    \n",
    "    # Stacking the existing base_model on top of the new prediction layer \n",
    "    fine_tuning_candidate = Model(inputs=pretrained_model.input, outputs=preds)\n",
    "    \n",
    "    # Optimizers. The hp parameter sets the iteration's compiler during the tuner search\n",
    "    adam = Adam(hp.Choice('learning_rate',values=LEARNING_RATES))\n",
    "    sgd = SGD(hp.Choice('learning_rate',values=LEARNING_RATES))\n",
    "    rmsprop = RMSprop(hp.Choice('learning_rate',values=LEARNING_RATES))\n",
    "    nadam = Nadam(hp.Choice('learning_rate',values=LEARNING_RATES))\n",
    "    adadelta = Adadelta(hp.Choice('learning_rate',values=LEARNING_RATES))\n",
    "    \n",
    "    optimizer = hp.Choice('optimizer', values = ['adam','sgd','rmsprop','nadam','adadelta'])\n",
    "    \n",
    "    # Compiling our candidate\n",
    "    fine_tuning_candidate.compile(optimizer=optimizer,\n",
    "                           loss = 'categorical_crossentropy',\n",
    "                           metrics = ['accuracy'])\n",
    "    \n",
    "    return fine_tuning_candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c53638b",
   "metadata": {},
   "source": [
    "### Step 2: Perform Tuner Search by defining metric to be optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ed4641f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 01m 22s]\n",
      "accuracy: 0.956250011920929\n",
      "\n",
      "Best accuracy So Far: 0.96875\n",
      "Total elapsed time: 00h 06m 39s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "    build_model,  # Pass the build_model function that defines the model architecture\n",
    "    keras_tuner.Objective(\"accuracy\", direction=\"max\"),  # Optimization objective \n",
    "    max_trials=5,\n",
    "    executions_per_trial=1,\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    # Finding the best set of hyperparameters to achieve optimal performance\n",
    "    training_dataset, \n",
    "    epochs = 6, \n",
    "    validation_data=validation_dataset,\n",
    "    steps_per_epoch = len(training_dataset)//32 , # Goes through all of the data\n",
    "    validation_steps=len(validation_dataset),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d00f270",
   "metadata": {},
   "source": [
    "### Step 3: Use the best parameters as the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a893a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.0001, 'optimizer': 'adam'}\n",
      "Epoch 1/20\n",
      "163/163 [==============================] - 380s 2s/step - loss: 0.7203 - accuracy: 0.9712 - val_loss: 3.1171e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "163/163 [==============================] - 369s 2s/step - loss: 0.1679 - accuracy: 0.9906 - val_loss: 4.4703e-08 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "163/163 [==============================] - 372s 2s/step - loss: 0.2049 - accuracy: 0.9893 - val_loss: 1.2367e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "163/163 [==============================] - 372s 2s/step - loss: 0.0757 - accuracy: 0.9956 - val_loss: 3.6809 - val_accuracy: 0.9375\n",
      "Epoch 5/20\n",
      "163/163 [==============================] - 370s 2s/step - loss: 0.0741 - accuracy: 0.9958 - val_loss: 1.2044 - val_accuracy: 0.9375\n",
      "Epoch 6/20\n",
      "163/163 [==============================] - 371s 2s/step - loss: 0.0697 - accuracy: 0.9958 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "163/163 [==============================] - 369s 2s/step - loss: 0.0192 - accuracy: 0.9981 - val_loss: 1.2795 - val_accuracy: 0.9375\n",
      "Epoch 8/20\n",
      "163/163 [==============================] - 369s 2s/step - loss: 0.0548 - accuracy: 0.9969 - val_loss: 3.0500 - val_accuracy: 0.9375\n",
      "Epoch 9/20\n",
      "163/163 [==============================] - 370s 2s/step - loss: 0.1406 - accuracy: 0.9946 - val_loss: 0.3469 - val_accuracy: 0.9375\n",
      "Epoch 10/20\n",
      "163/163 [==============================] - 368s 2s/step - loss: 0.0558 - accuracy: 0.9965 - val_loss: 2.9003 - val_accuracy: 0.9375\n",
      "Epoch 11/20\n",
      "163/163 [==============================] - 375s 2s/step - loss: 0.0454 - accuracy: 0.9981 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "163/163 [==============================] - 369s 2s/step - loss: 0.1078 - accuracy: 0.9958 - val_loss: 7.0816 - val_accuracy: 0.8750\n",
      "Epoch 13/20\n",
      "163/163 [==============================] - 371s 2s/step - loss: 0.0899 - accuracy: 0.9971 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "163/163 [==============================] - 370s 2s/step - loss: 0.0885 - accuracy: 0.9969 - val_loss: 15.9984 - val_accuracy: 0.8125\n",
      "Epoch 15/20\n",
      "163/163 [==============================] - 369s 2s/step - loss: 0.0395 - accuracy: 0.9975 - val_loss: 3.9083 - val_accuracy: 0.9375\n",
      "Epoch 16/20\n",
      "163/163 [==============================] - 370s 2s/step - loss: 0.0067 - accuracy: 0.9996 - val_loss: 11.6590 - val_accuracy: 0.8750\n",
      "Epoch 17/20\n",
      "163/163 [==============================] - 369s 2s/step - loss: 0.1578 - accuracy: 0.9948 - val_loss: 3.3138 - val_accuracy: 0.9375\n",
      "Epoch 18/20\n",
      "163/163 [==============================] - 370s 2s/step - loss: 0.2774 - accuracy: 0.9941 - val_loss: 7.1625 - val_accuracy: 0.8750\n",
      "Epoch 19/20\n",
      "163/163 [==============================] - 368s 2s/step - loss: 0.1425 - accuracy: 0.9965 - val_loss: 6.1853 - val_accuracy: 0.9375\n",
      "Epoch 20/20\n",
      "163/163 [==============================] - 369s 2s/step - loss: 0.0381 - accuracy: 0.9987 - val_loss: 3.9505 - val_accuracy: 0.9375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1af92209250>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Model\n",
    "print(tuner.get_best_hyperparameters()[0].values)\n",
    "\n",
    "# Fitting!\n",
    "model = tuner.get_best_models(num_models=1)[0]\n",
    "model.fit(training_dataset, \n",
    "    epochs = 20, \n",
    "    validation_data=validation_dataset,\n",
    "    steps_per_epoch = len(training_dataset),\n",
    "    validation_steps=len(validation_dataset),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a37b335",
   "metadata": {},
   "source": [
    "## Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc075a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 54). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\gabri\\OneDrive\\Desktop\\Coding\\A.I. and Machine Learning\\pneumonia-chest-xray/pneumonia_detector\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\gabri\\OneDrive\\Desktop\\Coding\\A.I. and Machine Learning\\pneumonia-chest-xray/pneumonia_detector\\assets\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "path = f\"{cwd}/pneumonia_detector\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    \n",
    "model.save(path) # Save\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5547a5",
   "metadata": {},
   "source": [
    "## Predicting and Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e68e6777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 43s 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal     0.9828    0.4872    0.6514       234\n",
      "   pneumonia     0.7638    0.9949    0.8641       390\n",
      "\n",
      "    accuracy                         0.8045       624\n",
      "   macro avg     0.8733    0.7410    0.7578       624\n",
      "weighted avg     0.8459    0.8045    0.7844       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from keras.models import load_model\n",
    "\n",
    "# Loading the model\n",
    "# model = load_model(path)\n",
    "\n",
    "\n",
    "# Making a prediction\n",
    "predictions = model.predict(testing_dataset)\n",
    "test_predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Evaluating predicted vs. true labels with one_hot_encoding\n",
    "test_true_labels = []\n",
    "for _, labels in testing_dataset:\n",
    "    test_true_labels.extend(labels.numpy())  # Convert the labels tensor to a numpy array and add it to the list\n",
    "\n",
    "test_true_labels = np.array(test_true_labels)  # Convert to NumPy array if not already\n",
    "\n",
    "def one_hot_to_category(one_hot_encoded, categories):\n",
    "    index = np.argmax(one_hot_encoded, axis=1)\n",
    "    return [categories[i] for i in index]\n",
    "\n",
    "test_true_labels = one_hot_to_category(test_true_labels,list(range(len(['normal', 'pneumonia']))))\n",
    "\n",
    "\n",
    "report = classification_report(test_true_labels, test_predicted_labels, target_names=['normal', 'pneumonia'], digits=4)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
